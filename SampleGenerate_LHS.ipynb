{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef090388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from knobs.knob_infos import spark, redis, rocksdb\n",
    "from pyDOE import *\n",
    "from scipy.stats.distributions import norm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cfeb9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_outlier(x, dict_dbms, key):\n",
    "    '''\n",
    "        x : normed_data\n",
    "        dict_dbms : dbms.continuous or dbms.numeric_cat or dbms.string_cat\n",
    "        key : knob name\n",
    "    '''\n",
    "    len_ = len(dict_dbms[key])\n",
    "        \n",
    "    if len_ == 3: # continuous data\n",
    "        x = np.where(x < dict_dbms[key][0], dict_dbms[key][0], x)\n",
    "        x = np.where(x > dict_dbms[key][1], dict_dbms[key][1], x)\n",
    "    elif len_ == 2:\n",
    "        x = np.where(x <= 0, 0, x)\n",
    "        x = np.where(x > len(dict_dbms[key][0])-1, len(dict_dbms[key][0])-1, x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a3fcf6",
   "metadata": {},
   "source": [
    "https://pythonhosted.org/pyDOE/randomized.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e484d8",
   "metadata": {},
   "source": [
    "# Single LHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b977af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Latin-Hypercube Sampling ### \n",
    "def LH_Sampling(dbms, sample_num):\n",
    "    lhd = lhs(len(dbms.knob_names), samples=sample_num)\n",
    "    \n",
    "    for i, k in enumerate(dbms.knob_names):\n",
    "        normed_data = norm(loc=dbms.mean[i], scale=dbms.std[i]).ppf(lhd[:, i])\n",
    "        normed_data = np.round(normed_data)\n",
    "        \n",
    "        # If the values are larger than maximum or less than minimum, set the values to be the maximum or minimum values.\n",
    "        if k in dbms.continuous_names:\n",
    "            normed_data = convert_outlier(normed_data, dbms.continuous, k)\n",
    "        if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "            normed_data = convert_outlier(normed_data, dbms.numeric_cat, k)\n",
    "        if dbms.string_cat_names is not None and k in dbms.string_cat_names:\n",
    "            normed_data = convert_outlier(normed_data, dbms.string_cat, k)\n",
    "\n",
    "        lhd[:, i] = normed_data\n",
    "    lhd = np.round(lhd)\n",
    "\n",
    "    # values of numeric_cat are index number so replace the index numbers to numerical values.\n",
    "    for i, k in enumerate(dbms.knob_names):\n",
    "        if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "            normed_data = lhd[:, i]\n",
    "            for n, idx in enumerate(normed_data):\n",
    "                normed_data[n] = dbms.numeric_cat[k][0][int(idx)]\n",
    "            lhd[:, i] = normed_data.astype(float)\n",
    "            \n",
    "    return lhd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4786f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "spark_samples = LH_Sampling(spark, 20)\n",
    "redis_samples = LH_Sampling(redis, 20)\n",
    "rocksdb_samples = LH_Sampling(rocksdb, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e9a17",
   "metadata": {},
   "source": [
    "# ADDB LHS - 1\n",
    "- Generate knobs in one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75ce18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDB_LHSampling(sample)\n",
    "sample_num = 10\n",
    "addb = [spark, redis, rocksdb]\n",
    "addb_name = ['spark', 'redis', 'rocksdb']\n",
    "addb_len = [len(spark.knob_names), len(redis.knob_names), len(rocksdb.knob_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58c96e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_knobs(f, selected_db, name, val):\n",
    "    if name in selected_db.continuous_names:\n",
    "        f.writelines(f'{name} {val}\\n')\n",
    "    if selected_db.numeric_cat_names is not None and name in selected_db.numeric_cat_names:\n",
    "        f.writelines(f'{name} {val}\\n')\n",
    "#         f.writelines(f'{name} {selected_db.numeric_cat[name][0][val]}\\n')\n",
    "    if selected_db.string_cat is not None and name in selected_db.string_cat_names:\n",
    "        f.writelines(f'{name} {selected_db.string_cat[name][0][val]}\\n')\n",
    "\n",
    "def create_conf_file(CONF_FILE, addb_sample, addb, addb_name, addb_len):\n",
    "    f = open(CONF_FILE, 'w')\n",
    "\n",
    "    for ld in range(len(addb)):\n",
    "        selected_db = addb[ld]\n",
    "        f.writelines(f'[{addb_name[ld]}]\\n')\n",
    "        for i, name in enumerate(selected_db.knob_names):\n",
    "            i += sum(addb_len[:ld])\n",
    "            selected_db = addb[ld]\n",
    "            val = int(addb_sample[i])\n",
    "            write_knobs(f, selected_db, name, val)\n",
    "            if i == addb_len[ld]:\n",
    "                cnt += 1\n",
    "#                 f.writelines(f'[{addb_name[cnt]}]\\n')\n",
    "        f.writelines('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f230799",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_addb_samples(sample_num, addb, addb_name, addb_len):\n",
    "    addb_lhd = lhs(sum(addb_len), samples=sample_num)\n",
    "\n",
    "    for a, dbms in enumerate(addb):\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            idx = sum(addb_len[:a]) + i\n",
    "            normed_data = norm(loc=dbms.mean[i], scale=dbms.std[i]).ppf(addb_lhd[:, idx])\n",
    "            normed_data = np.round(normed_data)\n",
    "\n",
    "            # If the values are larger than maximum or less than minimum, set the values to be the maximum or minimum values.\n",
    "            if k in dbms.continuous_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.continuous, k)\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.numeric_cat, k)\n",
    "            if dbms.string_cat_names is not None and k in dbms.string_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.string_cat, k)\n",
    "\n",
    "            addb_lhd[:, idx] = normed_data\n",
    "        addb_lhd = np.round(addb_lhd)\n",
    "\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                idx = sum(addb_len[:a]) + i\n",
    "                normed_data = addb_lhd[:, idx]\n",
    "                for n, data in enumerate(normed_data):\n",
    "                    normed_data[n] = dbms.numeric_cat[k][0][int(data)]\n",
    "                addb_lhd[:, idx] = normed_data.astype(float)\n",
    "    \n",
    "    addb_samples = addb_lhd\n",
    "    \n",
    "    CONF_PATH = 'configs/'\n",
    "    if os.path.isdir(CONF_PATH) is False:\n",
    "        os.mkdir(CONF_PATH)\n",
    "        \n",
    "    for num, addb_sample in enumerate(addb_samples):\n",
    "        CONF_NAME = f'addb_config{num}.conf'\n",
    "        create_conf_file(os.path.join(CONF_PATH, CONF_NAME), addb_sample, addb, addb_name, addb_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed84eac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_addb_samples(sample_num=5, addb=addb, addb_name=addb_name, addb_len=addb_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66163976",
   "metadata": {},
   "source": [
    "# ADDB LHS - 2\n",
    "- Generate knobs separated two files in master and slaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec002c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDB_LHSampling(sample)\n",
    "sample_num = 10\n",
    "addb = [spark, redis, rocksdb]\n",
    "addb_name = ['spark', 'redis', 'rocksdb']\n",
    "addb_len = [len(spark.knob_names), len(redis.knob_names), len(rocksdb.knob_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54f9526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_knobs(selected_db, name, val):\n",
    "    if name in selected_db.continuous_names:\n",
    "        knob_line = f'{name} {val}\\n'\n",
    "    if selected_db.numeric_cat_names is not None and name in selected_db.numeric_cat_names:\n",
    "        knob_line = f'{name} {val}\\n'\n",
    "#         f.writelines(f'{name} {selected_db.numeric_cat[name][0][val]}\\n')\n",
    "    if selected_db.string_cat is not None and name in selected_db.string_cat_names:\n",
    "        knob_line = f'{name} {selected_db.string_cat[name][0][val]}\\n'\n",
    "    return knob_line\n",
    "\n",
    "def create_conf_file(CONF_FILE, addb_sample, addb, addb_name, addb_len):\n",
    "    f = open(CONF_FILE, 'w')\n",
    "    file_inputs = []\n",
    "    cnt = 0\n",
    "    for ld in range(len(addb)):\n",
    "        selected_db = addb[ld]\n",
    "        file_inputs.append(f'[{addb_name[ld]}]\\n')\n",
    "        for i, name in enumerate(selected_db.knob_names):\n",
    "            i += sum(addb_len[:ld])\n",
    "            selected_db = addb[ld]\n",
    "            val = int(addb_sample[i])\n",
    "            file_inputs.append(write_knobs(selected_db, name, val))\n",
    "            if i == addb_len[ld]:\n",
    "                cnt += 1\n",
    "        file_inputs.append('\\n')\n",
    "    f.writelines(file_inputs[:-1])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de5d1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_addb_samples(sample_num, addb, addb_name, addb_len):\n",
    "    addb_lhd = lhs(sum(addb_len), samples=sample_num)\n",
    "\n",
    "    for a, dbms in enumerate(addb):\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            idx = sum(addb_len[:a]) + i\n",
    "            normed_data = norm(loc=dbms.mean[i], scale=dbms.std[i]).ppf(addb_lhd[:, idx])\n",
    "            normed_data = np.round(normed_data)\n",
    "\n",
    "            # If the values are larger than maximum or less than minimum, set the values to be the maximum or minimum values.\n",
    "            if k in dbms.continuous_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.continuous, k)\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.numeric_cat, k)\n",
    "            if dbms.string_cat_names is not None and k in dbms.string_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.string_cat, k)\n",
    "\n",
    "            addb_lhd[:, idx] = normed_data\n",
    "        addb_lhd = np.round(addb_lhd)\n",
    "\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                idx = sum(addb_len[:a]) + i\n",
    "                normed_data = addb_lhd[:, idx]\n",
    "                for n, data in enumerate(normed_data):\n",
    "                    normed_data[n] = dbms.numeric_cat[k][0][int(data)]\n",
    "                addb_lhd[:, idx] = normed_data.astype(float)\n",
    "    \n",
    "    addb_samples = addb_lhd\n",
    "    \n",
    "    MASTER_PATH = 'configs/master/'\n",
    "    SLAVE_PATH = 'configs/slave/'\n",
    "    if os.path.isdir(MASTER_PATH) is False:\n",
    "        os.mkdir(MASTER_PATH)\n",
    "    if os.path.isdir(SLAVE_PATH) is False:\n",
    "        os.mkdir(SLAVE_PATH)\n",
    "        \n",
    "    for num, addb_sample in enumerate(addb_samples):\n",
    "        CONF_NAME = f'addb_config{num}.conf'\n",
    "        create_conf_file(os.path.join(MASTER_PATH, CONF_NAME), addb_sample[:addb_len[0]], addb[:1], addb_name[:1], addb_len[:1])\n",
    "        create_conf_file(os.path.join(SLAVE_PATH, CONF_NAME), addb_sample[addb_len[0]:], addb[1:], addb_name[1:], addb_len[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e8836596",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_addb_samples(sample_num=1, addb=addb, addb_name=addb_name, addb_len=addb_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61a1c1b",
   "metadata": {},
   "source": [
    "# ADDB LHS - 3\n",
    "- Generate knobs separated three files in master, slaves-redis and slave-rocksdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e38a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDB_LHSampling(sample)\n",
    "sample_num = 100\n",
    "addb = [spark, redis, rocksdb]\n",
    "addb_name = ['spark', 'redis', 'rocksdb']\n",
    "addb_len = [len(spark.knob_names), len(redis.knob_names), len(rocksdb.knob_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b19376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_knobs(selected_db, name, val):\n",
    "    if name in selected_db.continuous_names:\n",
    "        knob_line = f'{name} {val}\\n'\n",
    "    if selected_db.numeric_cat_names is not None and name in selected_db.numeric_cat_names:\n",
    "        knob_line = f'{name} {val}\\n'\n",
    "#         f.writelines(f'{name} {selected_db.numeric_cat[name][0][val]}\\n')\n",
    "    if selected_db.string_cat is not None and name in selected_db.string_cat_names:\n",
    "        knob_line = f'{name} {selected_db.string_cat[name][0][val]}\\n'\n",
    "    return knob_line\n",
    "\n",
    "def create_conf_file(CONF_FILE, addb_sample, addb, addb_name, addb_len):\n",
    "    f = open(CONF_FILE, 'w')\n",
    "    file_inputs = []\n",
    "    cnt = 0\n",
    "    for ld in range(len(addb)):\n",
    "        selected_db = addb[ld]\n",
    "        file_inputs.append(f'[{addb_name[ld]}]\\n')\n",
    "        for i, name in enumerate(selected_db.knob_names):\n",
    "            i += sum(addb_len[:ld])\n",
    "            selected_db = addb[ld]\n",
    "            val = int(addb_sample[i])\n",
    "            file_inputs.append(write_knobs(selected_db, name, val))\n",
    "            if i == addb_len[ld]:\n",
    "                cnt += 1\n",
    "        file_inputs.append('\\n')\n",
    "    f.writelines(file_inputs[:-1])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f3641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_addb_samples(sample_num, addb, addb_name, addb_len):\n",
    "    addb_lhd = lhs(sum(addb_len), samples=sample_num)\n",
    "\n",
    "    for a, dbms in enumerate(addb):\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            idx = sum(addb_len[:a]) + i\n",
    "            normed_data = norm(loc=dbms.mean[i], scale=dbms.std[i]).ppf(addb_lhd[:, idx])\n",
    "            normed_data = np.round(normed_data)\n",
    "\n",
    "            # If the values are larger than maximum or less than minimum, set the values to be the maximum or minimum values.\n",
    "            if k in dbms.continuous_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.continuous, k)\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.numeric_cat, k)\n",
    "            if dbms.string_cat_names is not None and k in dbms.string_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.string_cat, k)\n",
    "\n",
    "            addb_lhd[:, idx] = normed_data\n",
    "        addb_lhd = np.round(addb_lhd)\n",
    "\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                idx = sum(addb_len[:a]) + i\n",
    "                normed_data = addb_lhd[:, idx]\n",
    "                for n, data in enumerate(normed_data):\n",
    "                    normed_data[n] = dbms.numeric_cat[k][0][int(data)]\n",
    "                addb_lhd[:, idx] = normed_data.astype(float)\n",
    "    \n",
    "    addb_samples = addb_lhd\n",
    "    \n",
    "    MASTER_PATH = 'configs/master/'\n",
    "    SLAVE_REDIS_PATH = 'configs/slave/redis'\n",
    "    SLAVE_ROCKSDB_PATH = 'configs/slave/rocksdb'\n",
    "    if os.path.isdir(MASTER_PATH) is False:\n",
    "        os.mkdir(MASTER_PATH)\n",
    "    if os.path.isdir(SLAVE_REDIS_PATH) is False:\n",
    "        os.mkdir(SLAVE_REDIS_PATH)\n",
    "    if os.path.isdir(SLAVE_ROCKSDB_PATH) is False:\n",
    "        os.mkdir(SLAVE_ROCKSDB_PATH)\n",
    "        \n",
    "    for num, addb_sample in enumerate(addb_samples):\n",
    "        CONF_NAME = f'addb_config{num}.conf'\n",
    "        create_conf_file(CONF_FILE=os.path.join(MASTER_PATH, CONF_NAME), \n",
    "                         addb_sample=addb_sample[:addb_len[0]], \n",
    "                         addb=[addb[0]], \n",
    "                         addb_name=[addb_name[0]], \n",
    "                         addb_len=[addb_len[0]])\n",
    "        create_conf_file(CONF_FILE=os.path.join(SLAVE_REDIS_PATH, CONF_NAME), \n",
    "                         addb_sample=addb_sample[addb_len[0]:addb_len[0]+addb_len[1]], \n",
    "                         addb=[addb[1]], \n",
    "                         addb_name=[addb_name[1]], \n",
    "                         addb_len=[addb_len[1]])\n",
    "        create_conf_file(CONF_FILE=os.path.join(SLAVE_ROCKSDB_PATH, CONF_NAME), \n",
    "                         addb_sample=addb_sample[-addb_len[2]:],\n",
    "                         addb=[addb[2]], \n",
    "                         addb_name=[addb_name[2]], \n",
    "                         addb_len=[addb_len[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d6add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_addb_samples(sample_num=sample_num, addb=addb, addb_name=addb_name, addb_len=addb_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950faf7",
   "metadata": {},
   "source": [
    "# Spark LHS\n",
    "- Generate knobs for spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fe5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDB_LHSampling(sample)\n",
    "sample_num = 10\n",
    "addb = [spark]\n",
    "addb_name = ['spark']\n",
    "addb_len = [len(spark.knob_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fa92a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_knobs(selected_db, name, val):\n",
    "    if name in selected_db.continuous_names:\n",
    "        knob_line = f'{name} {int(val)}\\n'\n",
    "    if selected_db.numeric_cat_names is not None and name in selected_db.numeric_cat_names:\n",
    "        knob_line = f'{name} {val}\\n'\n",
    "#         f.writelines(f'{name} {selected_db.numeric_cat[name][0][val]}\\n')\n",
    "    if selected_db.string_cat is not None and name in selected_db.string_cat_names:\n",
    "        knob_line = f'{name} {selected_db.string_cat[name][0][int(val)]}\\n'\n",
    "    return knob_line\n",
    "\n",
    "def create_conf_file(CONF_FILE, addb_sample, addb, addb_name, addb_len):\n",
    "    f = open(CONF_FILE, 'w')\n",
    "    file_inputs = []\n",
    "    cnt = 0\n",
    "    for ld in range(len(addb)):\n",
    "        selected_db = addb[ld]\n",
    "        file_inputs.append(f'[{addb_name[ld]}]\\n')\n",
    "        for i, name in enumerate(selected_db.knob_names):\n",
    "            i += sum(addb_len[:ld])\n",
    "            selected_db = addb[ld]\n",
    "#             val = int(addb_sample[i])\n",
    "            val = addb_sample[i]\n",
    "            file_inputs.append(write_knobs(selected_db, name, val))\n",
    "            if i == addb_len[ld]:\n",
    "                cnt += 1\n",
    "        file_inputs.append('\\n')\n",
    "    f.writelines(file_inputs[:-1])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9e33843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spark_samples(sample_num, addb, addb_name, addb_len):\n",
    "    addb_lhd = lhs(sum(addb_len), samples=sample_num)\n",
    "\n",
    "    for a, dbms in enumerate(addb):\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            idx = sum(addb_len[:a]) + i\n",
    "            normed_data = norm(loc=dbms.mean[i], scale=dbms.std[i]).ppf(addb_lhd[:, idx])\n",
    "            normed_data = np.round(normed_data)\n",
    "\n",
    "            # If the values are larger than maximum or less than minimum, set the values to be the maximum or minimum values.\n",
    "            if k in dbms.continuous_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.continuous, k)\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.numeric_cat, k)\n",
    "            if dbms.string_cat_names is not None and k in dbms.string_cat_names:\n",
    "                normed_data = convert_outlier(normed_data, dbms.string_cat, k)\n",
    "\n",
    "            addb_lhd[:, idx] = normed_data\n",
    "        addb_lhd = np.round(addb_lhd)\n",
    "\n",
    "        for i, k in enumerate(dbms.knob_names):\n",
    "            if dbms.numeric_cat_names is not None and k in dbms.numeric_cat_names:\n",
    "                idx = sum(addb_len[:a]) + i\n",
    "                normed_data = addb_lhd[:, idx]\n",
    "                for n, data in enumerate(normed_data):\n",
    "                    normed_data[n] = dbms.numeric_cat[k][0][int(data)]\n",
    "                addb_lhd[:, idx] = normed_data.astype(float)\n",
    "    \n",
    "    addb_samples = addb_lhd\n",
    "    \n",
    "    CONFIG_PATH = 'configs/spark'\n",
    "    if os.path.isdir(CONFIG_PATH) is False:\n",
    "        os.mkdir(CONFIG_PATH)\n",
    "        \n",
    "    for num, addb_sample in enumerate(addb_samples):\n",
    "        CONF_NAME = f'addb_config{num}.conf'\n",
    "        create_conf_file(os.path.join(CONFIG_PATH, CONF_NAME), addb_sample, addb, addb_name, addb_len)\n",
    "#         create_conf_file(os.path.join(SLAVE_PATH, CONF_NAME), addb_sample[addb_len[0]:], addb[1:], addb_name[1:], addb_len[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70909d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_spark_samples(sample_num=1000, addb=addb, addb_name=addb_name, addb_len=addb_len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[py3.7]",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
